{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition Custom Label Introduction\n",
    "With Amazon Rekognition Custom Labels, you can identify the objects and scenes in images that are specific to your business needs. For example, you can find your logo in social media posts, identify your products on store shelves, classify machine parts in an assembly line, distinguish healthy and infected plants etc.\n",
    "\n",
    "Rekognition Custom Labels builds off of Rekognitionâ€™s existing capabilities, which are already trained on tens of millions of images across many categories. So, it uses transfer learning to build the ML model. \n",
    "\n",
    "<br />\n",
    "\n",
    "![]url(./1a.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary set-up\n",
    "\n",
    "1. Once you are loggged in to the console, first step is create a S3 bucket where you will upload the images. \n",
    "2. Download the images from the google drive link https://drive.google.com/drive/folders/1Z_B1BDM9x9PdJ7A226_MWyKQ-DMj34Tf?usp=sharing and unzip it.\n",
    "\n",
    "3. Create a S3 bucket and upload images\n",
    "    - Type \"s3\" in the search bar and open the S3 bucket console. \n",
    "    - Create a S3 bucket with a unique name. The names have to be globally unique and all lower cap.\n",
    "    - Example: '2022-nimblevision-chinnayya-waterlevel' and '2022-nimblevision-anu-waterlevel'\n",
    "    - Open the S3 bucket that you created and choose \"upload\" > \"Add Folder\". select Level_50 and Level_75 folders one by one.\n",
    "    - Verify that the images are successfully uploaded in corresponding folders (50 and 75)\n",
    "    \n",
    "4. Open the manifest file and change the s3 bucket name rto yo was sent over email to the same S3 bucket that you created\n",
    "    - Import the manifest file to the same S3 bucket that you created\n",
    "\n",
    "5. Create a SageMaker notebook instance.\n",
    "    - open SageMaker console in another tab and under images, click on \"Notebook\" > \"Notebook Instances\"\n",
    "    - Click on \"create notebook instance\"\n",
    "    - Give a notebook instance name. Don't use any symbol in the name.\n",
    "    - Under \"Permissions and encryption\", create a new IAM role.\n",
    "    - Then create new instance. It will take few min to create the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition Custom Label Dataset Creation\n",
    "\n",
    "Choose custom label and click \"Get started\" \n",
    "   - if you are using rekognition custom label for the first time, it will prompt you to create a S3 bucket. Please create it. The bucket will be automatically created by custom label and all the labelling and modelling artifacts will be stored here.\n",
    "    \n",
    "   - Click \"Projects\" > \"Create project\". Give project name and create project. Once the project is created you should see the below screen\n",
    "   \n",
    "   - Click on \"Create dataset\" and select \"Start with a single dataset\" \n",
    "   \n",
    "   - Select \"Import images labeled by SageMaker Ground Truth\" \n",
    "   \n",
    "\n",
    "<br />\n",
    "\n",
    "![](./2a.png)\n",
    "   \n",
    "   \n",
    "   \n",
    "   - Go to your S3 bucket. Select (tick) the manifest file, copy the S3 URI and paste it in the S3 URI location in console.\n",
    "   \n",
    "   - Create the dataset\n",
    "   \n",
    "   - Now you should see the images with boxes drawn around the float switch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition Custom Label Model Training\n",
    "\n",
    "1. Now click on \"Train model\". Model training will take ~1 hour. In the console, if you select your project, you should see a status like TRAINING_IN_PROGRESS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition Custom Label Model Metric Verification\n",
    "\n",
    "Once the model is traine, you should be able to see the results\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "![Flow](./3a.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model for inference\n",
    "\n",
    "Now you can open JupyterLab and import the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and necessary set-up\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "import math\n",
    "\n",
    "client=boto3.client('rekognition')\n",
    "s3 = boto3.client('s3')\n",
    "s3_connection = boto3.resource('s3')\n",
    "\n",
    "bucket='rekognition-projects-2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start the model from the console. You can select \"use model\" tab and click on \"Start model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model can also be started by using the below code, but we will ignore it for now.\n",
    "\n",
    "import boto3\n",
    "\n",
    "def start_model(project_arn, model_arn, version_name, min_inference_units):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    try:\n",
    "        # Start the model\n",
    "        print('Starting model: ' + model_arn)\n",
    "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
    "        # Wait for the model to be in the running state\n",
    "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
    "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
    "\n",
    "        #Get the running status\n",
    "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
    "            VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Done...')\n",
    "    \n",
    "def main():\n",
    "    project_arn='arn:aws:rekognition:us-east-1:462768798410:project/water-level/1643853256248'\n",
    "    model_arn='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "    min_inference_units=1 \n",
    "    version_name='water-level.2022-02-03T15.23.44'\n",
    "    start_model(project_arn, model_arn, version_name, min_inference_units)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Test Images from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = \"water-level-detection/Level_50/IMG_0402.JPG\" #level 50\n",
    "img = \"water-level-detection/Level_75/IMG_0281.JPG\" #level 75\n",
    "#img = \"water-level-detection/Level_75/IMG_0297.JPG\" #level 75\n",
    "#img = \"water-level-detection/Level_50/IMG_0410.JPG\" #level 50\n",
    "\n",
    "ratio_tankheight_bbdiag = 0.261 # ratio of actual tank height to the bounding box diagonal\n",
    "\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket, 'Key': img}), width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(bucket,img,response):\n",
    "    # Load image from S3 bucket\n",
    "\n",
    "    s3_object = s3_connection.Object(bucket,img)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "\n",
    "    # Ready image to draw bounding boxes on it.\n",
    "    imgWidth, imgHeight = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "  \n",
    "    # calculate and display bounding boxes for each detected custom label\n",
    "    for customLabel in response['CustomLabels']:\n",
    " \n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left = imgWidth * box['Left']\n",
    "            top = imgHeight * box['Top']\n",
    "            width = imgWidth * box['Width']\n",
    "            height = imgHeight * box['Height']\n",
    "            diag = round(math.sqrt(width**2+height**2))\n",
    "            waterlevel = round(diag*ratio_tankheight_bbdiag)\n",
    "            print(\"water level is at approx.: \", waterlevel, \" cm\")\n",
    "\n",
    "            fnt = ImageFont.truetype(\"/usr/share/fonts/dejavu/DejaVuSans-Bold.ttf\", 65)\n",
    "            # use red for level 50 and blue for level 75\n",
    "            if (customLabel['Name'] == \"Level_50\"):\n",
    "                fontColor = \"red\"\n",
    "            else:\n",
    "                fontColor = \"blue\"\n",
    "                \n",
    "            draw.text((left,top-100), customLabel['Name'], fontColor, font=fnt)\n",
    "\n",
    "            points = (\n",
    "                (left,top),\n",
    "                (left + width, top),\n",
    "                (left + width, top + height),\n",
    "                (left , top + height),\n",
    "                (left, top))\n",
    "            draw.line(points, fill='#00d400', width=5)\n",
    "\n",
    "    image.show()\n",
    "    \n",
    "\n",
    "def show_custom_labels(model,bucket,img, min_confidence):\n",
    "\n",
    "    # Call DetectCustomLabels\n",
    "    response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': img}},\n",
    "        MinConfidence=min_confidence,\n",
    "        ProjectVersionArn=model)\n",
    "    \n",
    "    # display image.\n",
    "    display_image(bucket,img,response)\n",
    "\n",
    "    #return the json response\n",
    "    return (json.dumps(response['CustomLabels'], indent=2))\n",
    "\n",
    "def main():\n",
    "\n",
    "    model='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "    min_confidence=50\n",
    "\n",
    "    label_count=show_custom_labels(model,bucket,img, min_confidence)\n",
    "    print(\"Custom labels detected: \" + str(label_count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate water level to bounding box diag ratio based on the images from a S3 folder containing images\n",
    "\n",
    "def ratio_tankheight_bbdiag(bucket,key, level):\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=BUCKET, Prefix=KEY)\n",
    "    sum=0\n",
    "    count=0\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            img=obj['Key']\n",
    "            s3_object = s3_connection.Object(BUCKET,img)\n",
    "            s3_response = s3_object.get()\n",
    "\n",
    "            stream = io.BytesIO(s3_response['Body'].read())\n",
    "            image=Image.open(stream)\n",
    "\n",
    "            imgWidth, imgHeight = image.size\n",
    "            response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': img}}, MinConfidence=min_confidence, ProjectVersionArn=model)\n",
    "            for customLabel in response['CustomLabels']:\n",
    "\n",
    "                if 'Geometry' in customLabel:\n",
    "                    box = customLabel['Geometry']['BoundingBox']\n",
    "                    left = imgWidth * box['Left']\n",
    "                    top = imgHeight * box['Top']\n",
    "                    width = imgWidth * box['Width']\n",
    "                    height = imgHeight * box['Height']\n",
    "                    diag = round(math.sqrt(width**2+height**2))\n",
    "                    sum+=diag\n",
    "                    count+=1\n",
    "                    avgdiag=sum/count               \n",
    "    ratio=(tank_height*level/(100*avgdiag))\n",
    "    return(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate water level to bounding box diag ratio for level 50\n",
    "\n",
    "BUCKET = 'rekognition-projects-2022'\n",
    "KEY = 'water-level-detection/Level_50/'\n",
    "tank_height = 150\n",
    "level=50\n",
    "model='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "min_confidence=50\n",
    "model_arn='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "\n",
    "ratio_tankheight_bbdiag(BUCKET,KEY,level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate water level to bounding box diag ratio for level 75\n",
    "\n",
    "BUCKET = 'rekognition-projects-2022'\n",
    "KEY = 'water-level-detection/Level_75/'\n",
    "level=75\n",
    "model='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "model_arn='arn:aws:rekognition:us-east-1:462768798410:project/water-level/version/water-level.2022-02-03T15.23.44/1643873024451'\n",
    "\n",
    "ratio_tankheight_bbdiag(BUCKET,KEY,level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get more levels to get an accurate estimate of the ratio of water level to bounding box diag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
